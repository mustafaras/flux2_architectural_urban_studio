{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {"language": "markdown"},
      "source": [
        "# FLUX.2 Tutorial Notebook\n",
        "\n",
        "This notebook covers:\n",
        "1. Basic generation\n",
        "2. Batch processing\n",
        "3. Model comparison\n",
        "4. API integration\n",
        "5. Custom pipeline wrappers\n",
        "\n",
        "> Set `DRY_RUN = False` only after local models are configured."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {"language": "python"},
      "source": [
        "from pathlib import Path\n",
        "from flux2.streamlit_adapter import get_adapter\n",
        "\n",
        "DRY_RUN = True\n",
        "OUTPUT_DIR = Path('outputs/notebook')\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print('DRY_RUN =', DRY_RUN)\n",
        "print('Output dir:', OUTPUT_DIR.resolve())"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {"language": "python"},
      "source": [
        "adapter = get_adapter()\n",
        "model_id = 'flux.2-klein-4b'\n",
        "\n",
        "if DRY_RUN:\n",
        "    print(f'[DRY_RUN] Would load model: {model_id}')\n",
        "else:\n",
        "    adapter.load(model_id, dtype_str='bf16', cpu_offloading=False, attn_slicing=False)\n",
        "    print('Model loaded:', model_id)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {"language": "python"},
      "source": [
        "prompt = 'A serene mountain landscape at sunset'\n",
        "request = dict(prompt=prompt, num_steps=4, guidance=3.5, width=768, height=768, seed=42)\n",
        "\n",
        "if DRY_RUN:\n",
        "    print('[DRY_RUN] generate request:', request)\n",
        "else:\n",
        "    image = adapter.generate(**request)\n",
        "    out = OUTPUT_DIR / 'basic_generation.png'\n",
        "    image.save(out)\n",
        "    print('Saved:', out)\n",
        "    image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {"language": "python"},
      "source": [
        "batch_prompts = [\n",
        "    'A red sports car in studio lighting',\n",
        "    'A blue vintage airplane over mountains',\n",
        "    'A green forest trail with mist'\n",
        "]\n",
        "\n",
        "for idx, text in enumerate(batch_prompts, start=1):\n",
        "    req = dict(prompt=text, num_steps=4, guidance=3.5, width=768, height=768, seed=100 + idx)\n",
        "    if DRY_RUN:\n",
        "        print(f'[DRY_RUN] batch {idx}:', req)\n",
        "    else:\n",
        "        img = adapter.generate(**req)\n",
        "        out = OUTPUT_DIR / f'batch_{idx}.png'\n",
        "        img.save(out)\n",
        "        print('Saved:', out)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {"language": "python"},
      "source": [
        "comparison_prompt = 'A cozy living room interior photo'\n",
        "models = ['flux.2-klein-4b', 'flux.2-klein-base-4b']\n",
        "\n",
        "for model in models:\n",
        "    if DRY_RUN:\n",
        "        print(f'[DRY_RUN] Would compare with model={model}')\n",
        "        continue\n",
        "\n",
        "    adapter.load(model, dtype_str='bf16')\n",
        "    img = adapter.generate(\n",
        "        prompt=comparison_prompt,\n",
        "        num_steps=4,\n",
        "        guidance=3.5,\n",
        "        width=768,\n",
        "        height=768,\n",
        "        seed=42,\n",
        "    )\n",
        "    out = OUTPUT_DIR / f'compare_{model}.png'\n",
        "    img.save(out)\n",
        "    print('Saved:', out)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {"language": "python"},
      "source": [
        "short_prompt = 'A cat'\n",
        "\n",
        "if DRY_RUN:\n",
        "    print('[DRY_RUN] upsample request:', short_prompt)\n",
        "else:\n",
        "    upsampled = adapter.upsample_prompt(\n",
        "        short_prompt,\n",
        "        backend='openrouter',\n",
        "        openrouter_model='mistralai/pixtral-large-2411',\n",
        "    )\n",
        "    print('Upsampled prompt:\n', upsampled)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {"language": "python"},
      "source": [
        "def generate_art(prompt: str, model_id: str = 'flux.2-klein-4b', *, seed: int = 42):\n",
        "    adapter = get_adapter()\n",
        "    if DRY_RUN:\n",
        "        return {'mode': 'dry_run', 'model': model_id, 'prompt': prompt, 'seed': seed}\n",
        "\n",
        "    adapter.load(model_id, dtype_str='bf16')\n",
        "    image = adapter.generate(\n",
        "        prompt=prompt,\n",
        "        num_steps=4,\n",
        "        guidance=3.5,\n",
        "        width=768,\n",
        "        height=768,\n",
        "        seed=seed,\n",
        "    )\n",
        "    out = OUTPUT_DIR / f'api_{seed}.png'\n",
        "    image.save(out)\n",
        "    return {'mode': 'real', 'output': str(out)}\n",
        "\n",
        "generate_art('A cinematic sci-fi city at dawn')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {"language": "python"},
      "source": [
        "class SafeGenerationPipeline:\n",
        "    def __init__(self, adapter):\n",
        "        self.adapter = adapter\n",
        "\n",
        "    def run(self, prompt: str, seed: int = 42):\n",
        "        if DRY_RUN:\n",
        "            return {'status': 'dry_run', 'prompt': prompt, 'seed': seed}\n",
        "        try:\n",
        "            return self.adapter.generate(\n",
        "                prompt=prompt,\n",
        "                num_steps=4,\n",
        "                guidance=3.5,\n",
        "                width=768,\n",
        "                height=768,\n",
        "                seed=seed,\n",
        "            )\n",
        "        except Exception as exc:\n",
        "            return {'status': 'failed', 'error': str(exc)}\n",
        "\n",
        "pipeline = SafeGenerationPipeline(adapter)\n",
        "pipeline.run('A minimalist product photo of a wristwatch')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {"language": "markdown"},
      "source": [
        "## Next Steps\n",
        "\n",
        "- Switch `DRY_RUN = False`\n",
        "- Ensure local model weights are configured\n",
        "- Re-run cells to produce actual outputs in `outputs/notebook/`"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
